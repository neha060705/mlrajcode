{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "train=pd.read_csv(\"/kaggle/input/mle-ese-mock/train (5).csv\")\n",
    "test=pd.read_csv(\"/kaggle/input/mle-ese-mock/test (4).csv\")\n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "test.isnull().sum()\n",
    "\n",
    "test_id=test['id']\n",
    "test=test.drop(columns=['id'])\n",
    "\n",
    "train=train.dropna(subset=['quality_grade'])\n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "X=train.drop(columns=['id','quality_grade'])\n",
    "y=train['quality_grade']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "numeric_features=X.select_dtypes(include=['int64','float64']).columns\n",
    "categorical_features=X.select_dtypes(include=['object']).columns\n",
    "\n",
    "numerical_pipeline=Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "categorical_pipeline=Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessing=ColumnTransformer(transformers=[\n",
    "    ('num',numerical_pipeline,numeric_features),\n",
    "    ('cat',categorical_pipeline,categorical_features)\n",
    "])\n",
    "\n",
    "rom sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "model = HistGradientBoostingClassifier(\n",
    "    loss=\"log_loss\",        # IMPORTANT\n",
    "    max_iter=100,\n",
    "    learning_rate=0.05,\n",
    "\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=30,\n",
    "\n",
    "    l2_regularization=0.1,\n",
    "    max_bins=255,\n",
    "\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "pipeline=Pipeline(steps=[\n",
    "    ('preprocessing',preprocessing),\n",
    "    ('model',model)\n",
    "])\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)  # fit on train\n",
    "y_test_enc = le.transform(y_test)        # transform test\n",
    "\n",
    "pipeline.fit(X_train,y_train_enc)\n",
    "\n",
    "y_proba=pipeline.predict_proba(X_test)\n",
    "\n",
    "loss = log_loss(y_test_enc, y_proba)\n",
    "print(\"Log Loss:\", loss)\n",
    "\n",
    "y_final=pipeline.predict_proba(test)\n",
    "\n",
    "class_names = le.classes_  # use label encoder mapping\n",
    "submission = pd.DataFrame(y_final, columns=[f\"Status_{cls}\" for cls in class_names])\n",
    "submission.insert(0, 'id', test_id)\n",
    "submission.to_csv(\"submission4.csv\", index=False)\n",
    "print(\"\\nâœ… Submission file created successfully!\")\n",
    "print(submission.head())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
